# AI Self-Querying Retriever

> **A professional-grade, multi-agent AI retrieval system** built with LangGraph, LangChain, Django, Node.js, and React/TypeScript. Features advanced RAG (Retrieval-Augmented Generation) techniques including self-querying retrieval, hybrid search, cross-encoder reranking, context compression, and query expansion.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![React 18](https://img.shields.io/badge/react-18-blue.svg)](https://reactjs.org/)
[![Django 5](https://img.shields.io/badge/django-5-green.svg)](https://www.djangoproject.com/)

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Key Features](#key-features)
- [Tech Stack](#tech-stack)
- [Quick Start](#quick-start)
- [Detailed Setup](#detailed-setup)
- [Usage Guide](#usage-guide)
- [API Documentation](#api-documentation)
- [LangGraph Agent System](#langgraph-agent-system)
- [Retrieval Methods](#retrieval-methods)
- [Augmentation Techniques](#augmentation-techniques)
- [Configuration](#configuration)
- [Development](#development)
- [Project Structure](#project-structure)
- [Observability](#observability)
- [Performance](#performance)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

---

## ðŸŽ¯ Overview

The AI Self-Querying Retriever is a sophisticated demonstration of state-of-the-art Retrieval-Augmented Generation (RAG) techniques. It showcases how to build production-ready AI applications that can intelligently search and retrieve information from large document collections using multiple strategies and advanced augmentation techniques.

### What Makes It Special?

- **ðŸ¤– Multi-Agent Architecture**: LangGraph-powered agent orchestration with dynamic pipeline construction
- **ðŸ” 5 Retrieval Strategies**: Vector, BM25, Hybrid, Self-Query, and Hypothetical Document Embeddings (HyDE)
- **âš¡ Advanced Augmentation**: Cross-encoder reranking, LLM-based compression, and query expansion
- **ðŸ“Š Real-Time Analytics**: Comprehensive dashboards for query trends, method comparison, and performance metrics
- **ðŸ”§ Full-Stack Application**: Production-ready with Docker, health checks, monitoring, and observability
- **ðŸŒ Modern Web Interface**: React + TypeScript with real-time WebSocket updates

### Use Cases

- **Enterprise Knowledge Management**: Index internal documentation and enable self-service Q&A
- **Research & Academic**: Scientific paper retrieval and literature review
- **Customer Support**: Knowledge base search with context-aware responses
- **Legal & Compliance**: Document discovery with metadata filtering
- **Content Management**: Enhanced CMS search with semantic understanding

---

## ðŸ—ï¸ Architecture

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRESENTATION LAYER                              â”‚
â”‚         React 18 + TypeScript + Vite + Tailwind CSS             â”‚
â”‚    Dashboard | Query UI | Documents | Analytics | Admin         â”‚
â”‚                     Port: 3088 (exposed)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API GATEWAY LAYER                               â”‚
â”‚              Node.js + Express + TypeScript                      â”‚
â”‚   Rate Limiting | CORS | Routing | WebSocket Manager            â”‚
â”‚                     Port: 3087 (exposed)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Django    â”‚  â”‚   MCP Server        â”‚  â”‚   LangFuse    â”‚
â”‚   Backend   â”‚  â”‚   (Port 3086)       â”‚  â”‚   (Port 3085) â”‚
â”‚  (Port 8083)â”‚  â”‚   Model Context     â”‚  â”‚  Observabilityâ”‚
â”‚             â”‚  â”‚   Protocol          â”‚  â”‚               â”‚
â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚  â”‚  â”‚
   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â”‚                                             â”‚
â”Œâ”€â”€â–¼â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
â”‚ PostgreSQL â”‚  â”‚    Redis    â”‚  â”‚     ChromaDB        â”‚
â”‚ (Port 5432)â”‚  â”‚ (Port 6379) â”‚  â”‚   (Port 8000)       â”‚
â”‚  Metadata  â”‚  â”‚ Cache/Queue â”‚  â”‚   Vector Store      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Layers

#### 1. **Presentation Layer** (Frontend)
- **React 18** with TypeScript for type safety
- **Vite** for fast development and optimized builds
- **Tailwind CSS** for modern, responsive UI
- **Zustand** for lightweight state management
- **9 Main Pages**: Dashboard, Query Interface, Documents, Collections, Agent Visualization, Analytics, Query History, Pipelines, Settings

#### 2. **API Gateway Layer**
- **Express.js** server acting as reverse proxy
- Rate limiting (200 requests per 15 minutes)
- CORS handling and security headers (Helmet)
- WebSocket connection management for real-time updates
- Request/response logging with correlation IDs
- Health check aggregation

#### 3. **Backend Application Layer**
- **Django 5** with Django REST Framework
- **LangGraph** multi-agent orchestration
- **Celery** for asynchronous task processing
- **Daphne** ASGI server for WebSocket support
- **ChromaDB** integration for vector search
- **OpenAI** integration for embeddings and LLM calls

#### 4. **Data & Infrastructure Layer**
- **PostgreSQL 16**: Primary database for metadata, queries, and documents
- **ChromaDB**: Vector database for embeddings
- **Redis 7**: Cache, Celery broker, and result backend
- **LangFuse**: Self-hosted LLM observability
- **Celery Flower**: Task queue monitoring

---

## âœ¨ Key Features

### Retrieval Methods

| Method | Description | Use Case | Latency |
|--------|-------------|----------|---------|
| **Vector Search** | Semantic similarity using OpenAI embeddings + ChromaDB | General semantic queries | 100-300ms |
| **Self-Querying** | LLM-constructed metadata filters from natural language | Complex filtered queries | 500-800ms |
| **BM25 Keyword** | Traditional keyword-based retrieval using BM25 algorithm | Exact keyword matching | 50-150ms |
| **Hybrid Search** | Ensemble of BM25 + vector search with weighted merge | Best of both worlds | 200-400ms |
| **Hypothetical Questions** | HyDE-style retrieval with generated questions | Abstract concept queries | 800-1200ms |

### Augmentation Techniques

- **ðŸŽ¯ Cross-Encoder Reranking**: Re-score results using `ms-marco-MiniLM-L-6-v2` for improved relevance (+200-500ms)
- **ðŸ—œï¸ Context Compression**: LLM-based extraction to filter irrelevant content and reduce token usage
- **ðŸ“ˆ Query Expansion**: Enhance queries with synonyms and alternative phrasings for better recall

### Multi-Agent System (LangGraph)

The system uses **11 specialized agents** orchestrated via LangGraph's StateGraph:

1. **Supervisor Agent**: Orchestrates the entire retrieval pipeline
2. **Query Analyzer**: Determines optimal retrieval strategy based on query analysis
3. **Self-Query Constructor**: Builds structured metadata filters from natural language
4. **Vector Retriever**: Performs vector similarity search via ChromaDB
5. **BM25 Retriever**: Performs keyword-based search
6. **Hybrid Merger**: Combines multi-strategy results with weighted scoring
7. **Hypothetical Question Generator**: Creates hypothetical questions for HyDE
8. **Reranker**: Cross-encoder reranking of results
9. **Compressor**: Context compression to reduce noise
10. **Query Expander**: Query enhancement with synonyms
11. **Answer Generator**: Final answer synthesis from retrieved documents

### Additional Features

- âœ… **MCP (Model Context Protocol)**: Standardized tool interface for retrieval operations
- âœ… **A2A (Agent-to-Agent)**: Inter-agent communication protocol with agent cards
- âœ… **LangSmith Integration**: LLM tracing and debugging
- âœ… **LangFuse Observability**: Self-hosted LLM monitoring and analytics
- âœ… **Real-time Streaming**: WebSocket-based streaming responses
- âœ… **Analytics Dashboard**: Query trends, method comparison, performance metrics
- âœ… **Pipeline Builder**: Configure and save custom retrieval pipelines
- âœ… **Document Management**: Upload, organize, and manage document collections
- âœ… **Celery Task Queue**: Asynchronous document processing and indexing
- âœ… **Health Checks**: Comprehensive health monitoring across all services
- âœ… **Docker Compose**: One-command deployment of entire stack

---

## ðŸ› ï¸ Tech Stack

### Frontend

| Technology | Version | Purpose |
|------------|---------|---------|
| React | 18 | UI framework |
| TypeScript | 5.x | Type safety |
| Vite | 5.x | Build tool |
| Tailwind CSS | 3.x | Styling |
| Zustand | 4.x | State management |
| Axios | 1.x | HTTP client |
| React Router | 6.x | Routing |
| Lucide React | Latest | Icons |

### Backend

| Technology | Version | Purpose |
|------------|---------|---------|
| Django | 5.0 | Web framework |
| Django REST Framework | 3.x | API framework |
| Daphne | 4.x | ASGI server |
| LangChain | 0.3.21 | LLM framework |
| LangGraph | Latest | Agent orchestration |
| Celery | 5.x | Task queue |
| psycopg2 | 2.9 | PostgreSQL driver |
| redis-py | 5.x | Redis client |
| chromadb | 0.6.3 | Vector DB client |
| sentence-transformers | Latest | Reranking models |

### API Gateway

| Technology | Version | Purpose |
|------------|---------|---------|
| Node.js | 20.x | Runtime |
| Express | 4.x | Web framework |
| TypeScript | 5.x | Type safety |
| ws | 8.x | WebSocket support |
| axios | 1.x | HTTP client |
| helmet | 7.x | Security headers |
| express-rate-limit | 7.x | Rate limiting |

### Infrastructure

| Service | Version | Port | Purpose |
|---------|---------|------|---------|
| PostgreSQL | 16 | 5432 | Primary database |
| Redis | 7 | 6379 | Cache + broker |
| ChromaDB | 0.6.3 | 8000 | Vector database |
| LangFuse | 2.x | 3085 | Observability |
| Celery Flower | Latest | 5583 | Task monitoring |

### AI/ML

| Service | Model | Purpose |
|---------|-------|---------|
| OpenAI Embeddings | text-embedding-ada-002 | Document embeddings |
| OpenAI LLM | gpt-4o-mini | Query analysis, answer generation |
| HuggingFace | ms-marco-MiniLM-L-6-v2 | Cross-encoder reranking |

---

## ðŸš€ Quick Start

### Prerequisites

Before you begin, ensure you have:

- **Docker** (version 20.10+) and **Docker Compose** (version 2.0+)
- **OpenAI API key** ([Get one here](https://platform.openai.com/api-keys))
- **Minimum 4GB RAM** and **10GB disk space**
- **Linux, macOS, or Windows with WSL2**

### Installation (5 minutes)

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/self-querying-retriever.git
cd self-querying-retriever

# 2. Configure environment variables
cp .env.example .env

# 3. Edit .env and add your OpenAI API key
nano .env  # or use your favorite editor
# Set: OPENAI_API_KEY=sk-...

# 4. Start all services with Docker Compose
docker-compose up -d

# 5. Wait for services to initialize (30-60 seconds)
docker-compose logs -f backend  # Watch startup logs

# 6. Initialize database and seed sample data
docker-compose exec backend python manage.py migrate
docker-compose exec backend python manage.py createsuperuser --noinput --email admin@example.com
docker-compose exec backend python manage.py seed_documents --no-input
```

### Access the Application

| Service | URL | Credentials |
|---------|-----|-------------|
| **Main Application** | http://localhost:3088 | - |
| API Gateway | http://localhost:3087 | - |
| Django Admin | http://localhost:8083/admin/ | admin@example.com / admin |
| LangFuse Dashboard | http://localhost:3085 | admin@example.com / changeme123 |
| Celery Flower | http://localhost:5583 | - |
| MCP Server | http://localhost:3086 | - |

### Your First Query

1. Navigate to http://localhost:3088/query
2. Enter a query: `"What are the latest advancements in solar power?"`
3. Select retrieval method: **Vector Search** (recommended for first try)
4. Click **Search** and view results!

---

## ðŸ“š Detailed Setup

### Step 1: Environment Configuration

The `.env` file contains all configuration. Key variables:

```bash
# Required
OPENAI_API_KEY=sk-...                    # Your OpenAI API key

# Optional - LangSmith (for LLM tracing)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...

# Optional - LangFuse (self-hosted observability)
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=http://langfuse:3000

# Database (change in production)
POSTGRES_DB=self_querying_retriever
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=db
POSTGRES_PORT=5432

# Redis
REDIS_HOST=redis
REDIS_PORT=6379

# ChromaDB
CHROMA_HOST=chromadb
CHROMA_PORT=8000

# Django
DJANGO_SECRET_KEY=your-secret-key-here
DJANGO_DEBUG=True
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,172.168.1.95

# API Gateway
BACKEND_URL=http://backend:8083
MCP_SERVER_URL=http://mcp-server:3086
CORS_ALLOWED_ORIGINS=http://localhost:3088

# Frontend
VITE_API_URL=http://localhost:3087
VITE_WS_URL=ws://localhost:3087
```

### Step 2: Service Architecture

The `docker-compose.yml` orchestrates 9 services:

1. **db** (PostgreSQL): Primary database
2. **redis**: Cache and message broker
3. **chromadb**: Vector database
4. **langfuse**: Self-hosted observability platform
5. **backend**: Django application
6. **celery-worker**: Background task processor
7. **celery-beat**: Periodic task scheduler
8. **frontend**: React application
9. **api-gateway**: Express API gateway
10. **mcp-server**: Model Context Protocol server
11. **flower**: Celery monitoring UI

### Step 3: Database Migrations

```bash
# Run migrations
docker-compose exec backend python manage.py migrate

# Create superuser for Django admin
docker-compose exec backend python manage.py createsuperuser

# Seed sample renewable energy documents (100+ docs)
docker-compose exec backend python manage.py seed_documents --no-input

# Verify data
docker-compose exec backend python manage.py shell
>>> from retriever.models import Document, Collection
>>> Document.objects.count()
100
>>> Collection.objects.all()
<QuerySet [<Collection: Renewable Energy Collection>]>
```

### Step 4: Health Checks

Verify all services are healthy:

```bash
# Check all containers are running
docker-compose ps

# Check backend health
curl http://localhost:8083/api/health/

# Check API gateway health
curl http://localhost:3087/health

# Check ChromaDB
curl http://localhost:8000/api/v1/heartbeat

# View logs
docker-compose logs -f backend
docker-compose logs -f celery-worker
```

---

## ðŸ“– Usage Guide

### 1. Query Interface

The main query interface (`/query`) allows you to:

#### Basic Query
```
Query: "What are the benefits of solar energy?"
Method: Vector Search
Top K: 5
```

#### Advanced Query with Filters
```
Query: "renewable energy policies"
Method: Self-Query
Filters:
  - Year: 2024
  - Topics: ["policy", "government"]
  - Subtopic: "renewable energy"
Top K: 10
```

#### Augmented Query
```
Query: "latest wind turbine technology"
Method: Hybrid Search
Augmentation:
  âœ“ Enable Reranking
  âœ“ Enable Compression
  âœ— Query Expansion
```

### 2. Document Management

#### Upload Single Document
```bash
curl -X POST http://localhost:3087/api/documents/ \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Solar Power Innovations 2024",
    "content": "Full document text here...",
    "collection_name": "renewable_energy",
    "metadata": {
      "year": 2024,
      "topics": ["solar power", "innovation"],
      "subtopic": "renewable energy"
    }
  }'
```

#### Bulk Upload
```bash
curl -X POST http://localhost:3087/api/documents/bulk/ \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {"title": "Doc 1", "content": "...", "metadata": {...}},
      {"title": "Doc 2", "content": "...", "metadata": {...}}
    ],
    "collection_name": "renewable_energy"
  }'
```

### 3. Analytics Dashboard

Navigate to `/analytics` to view:
- **Query Trends**: Queries over time
- **Method Comparison**: Performance by retrieval method
- **Top Documents**: Most frequently retrieved documents
- **Execution Times**: Average latency by method

### 4. Pipeline Builder

Create custom pipelines at `/pipelines`:

```json
{
  "name": "My Custom Pipeline",
  "description": "Vector search with reranking",
  "config": {
    "retrieval_method": "vector",
    "top_k": 10,
    "enable_reranking": true,
    "enable_compression": false,
    "enable_expansion": false,
    "filters": {
      "year": 2024,
      "topics": ["solar power"]
    }
  }
}
```

### 5. Agent Visualization

View the LangGraph workflow at `/agents`:
- See real-time agent execution
- Visualize state transitions
- Debug agent decisions
- Replay past executions

---

## ðŸ”Œ API Documentation

### Authentication

Currently, the API is open (no authentication required). In production, implement:
- JWT tokens
- API keys
- OAuth2

### Query API

#### Submit Query

```http
POST /api/v1/retriever/query/
Content-Type: application/json

{
  "query_text": "What are renewable energy sources?",
  "retrieval_method": "vector",  // vector | self_query | bm25 | hybrid | hypothetical_questions
  "top_k": 5,
  "enable_reranking": true,
  "enable_compression": false,
  "enable_expansion": false,
  "filters": {
    "year": 2024,
    "topics": ["solar power", "wind energy"],
    "subtopic": "renewable energy"
  }
}
```

**Response:**
```json
{
  "query_id": 123,
  "results": [
    {
      "document_id": 456,
      "title": "Solar Power Innovations",
      "content": "Full document content...",
      "score": 0.89,
      "rank": 1,
      "metadata": {
        "year": 2024,
        "topics": ["solar power"],
        "subtopic": "renewable energy"
      }
    }
  ],
  "execution_time_ms": 834,
  "agent_trace": {
    "query_analyzer": {"time_ms": 245, "strategy": "vector"},
    "vector_retriever": {"time_ms": 312, "documents": 5},
    "reranker": {"time_ms": 277, "reranked": 5}
  }
}
```

### Document API

#### List Documents
```http
GET /api/v1/retriever/documents/?collection=renewable_energy&limit=20&offset=0
```

#### Get Document
```http
GET /api/v1/retriever/documents/{id}/
```

#### Create Document
```http
POST /api/v1/retriever/documents/
Content-Type: application/json

{
  "title": "Document Title",
  "content": "Document content...",
  "collection_name": "renewable_energy",
  "metadata": {
    "year": 2024,
    "topics": ["solar power"],
    "subtopic": "renewable energy"
  }
}
```

#### Bulk Upload (Async)
```http
POST /api/v1/retriever/documents/bulk-upload/
Content-Type: application/json

{
  "documents": [...],
  "collection_name": "renewable_energy"
}

Response: 202 Accepted
{
  "batch_id": "abc-123",
  "status": "processing",
  "message": "Processing 100 documents..."
}
```

### Collection API

#### List Collections
```http
GET /api/v1/retriever/collections/
```

#### Get Collection Stats
```http
GET /api/v1/retriever/collections/{id}/stats/

Response:
{
  "name": "Renewable Energy Collection",
  "document_count": 100,
  "total_queries": 543,
  "avg_execution_time_ms": 825,
  "embedding_model": "text-embedding-ada-002"
}
```

### Analytics API

#### Dashboard Stats
```http
GET /api/v1/retriever/analytics/

Response:
{
  "total_queries": 1234,
  "total_documents": 500,
  "avg_execution_time_ms": 850,
  "queries_today": 45,
  "method_distribution": {
    "vector": 0.45,
    "hybrid": 0.30,
    "self_query": 0.15,
    "bm25": 0.10
  }
}
```

#### Query Trends
```http
GET /api/v1/retriever/analytics/trends/?days=7

Response:
{
  "dates": ["2024-01-01", "2024-01-02", ...],
  "query_counts": [45, 67, 89, ...]
}
```

### Agent API

#### List Agents
```http
GET /api/v1/retriever/agents/
```

#### Agent Graph (Mermaid)
```http
GET /api/v1/retriever/agent-graph/

Response:
{
  "mermaid": "graph TD\n  START --> supervisor\n  ..."
}
```

#### Agent Executions
```http
GET /api/v1/retriever/agent-executions/?limit=10

Response:
{
  "results": [
    {
      "id": 1,
      "query": "renewable energy",
      "status": "completed",
      "execution_time_ms": 834,
      "trace": {...}
    }
  ]
}
```

---

## ðŸ¤– LangGraph Agent System

### State Management

The system uses a typed state dictionary (`RetrieverState`) that flows through all agents:

```python
class RetrieverState(TypedDict):
    query: str                          # Original user query
    expanded_query: Optional[str]       # After query expansion
    retrieval_method: str               # Selected method
    filters: Dict[str, Any]             # Metadata filters
    top_k: int                          # Number of results
    documents: List[Dict]               # Retrieved documents
    reranked_documents: List[Dict]      # After reranking
    compressed_documents: List[Dict]    # After compression
    final_documents: List[Dict]         # Final results
    answer: Optional[str]               # Generated answer
    agent_trace: Dict[str, Any]        # Execution trace
```

### Agent Workflow

```mermaid
graph TD
    START([User Query]) --> supervisor{Supervisor Agent}
    supervisor -->|analyze| query_analyzer[Query Analyzer]
    query_analyzer -->|extract filters| routing{Route by Method}

    routing -->|vector| vector_retriever[Vector Retriever]
    routing -->|self_query| self_query_constructor[Self-Query Constructor]
    routing -->|bm25| bm25_retriever[BM25 Retriever]
    routing -->|hybrid| hybrid_merger[Hybrid Merger]
    routing -->|hypothetical| hypo_question[Hypothetical Questions]

    self_query_constructor --> vector_retriever
    hybrid_merger --> merge[Merge Results]

    vector_retriever --> augmentation{Apply Augmentation?}
    bm25_retriever --> augmentation
    hypo_question --> augmentation
    merge --> augmentation

    augmentation -->|rerank| reranker[Cross-Encoder Reranker]
    augmentation -->|compress| compressor[Context Compressor]
    augmentation -->|expand| query_expander[Query Expander]
    augmentation -->|none| answer_generator[Answer Generator]

    reranker --> answer_generator
    compressor --> answer_generator
    query_expander -->|re-retrieve| vector_retriever

    answer_generator --> END([Results + Answer])
```

### Agent Descriptions

#### 1. Query Analyzer
**Purpose**: Analyze user query and determine optimal strategy

**Input**: User query string
**Output**: Extracted filters, selected retrieval method, expansion flag

**Example**:
```
Query: "Show me solar power documents from 2024"
Output: {
  "filters": {"year": 2024, "topics": ["solar power"]},
  "retrieval_method": "self_query",
  "enable_expansion": false
}
```

#### 2. Vector Retriever
**Purpose**: Semantic similarity search using embeddings

**Process**:
1. Generate query embedding via OpenAI
2. Search ChromaDB for similar vectors
3. Apply metadata filters if provided
4. Return top-k results

**Use When**: General semantic queries without specific keywords

#### 3. Self-Query Constructor
**Purpose**: LLM-constructed metadata filters

**Process**:
1. LLM extracts structured filters from natural language
2. Constructs ChromaDB where clause
3. Performs filtered vector search

**Use When**: Complex queries with implicit filters

#### 4. BM25 Retriever
**Purpose**: Keyword-based retrieval using TF-IDF

**Process**:
1. Tokenize query
2. Calculate BM25 scores against document corpus
3. Return top-k by score

**Use When**: Exact keyword matching needed

#### 5. Hybrid Merger
**Purpose**: Combine BM25 and vector search

**Process**:
1. Run both BM25 and vector retrievers in parallel
2. Merge results using weighted scoring (default: 0.5/0.5)
3. Remove duplicates
4. Re-rank by combined score

**Use When**: Want best of both semantic and keyword search

#### 6. Reranker
**Purpose**: Re-score results using cross-encoder

**Process**:
1. Load ms-marco-MiniLM-L-6-v2 model
2. Compute cross-encoder scores for query-document pairs
3. Re-rank by new scores

**Use When**: Need highest relevance accuracy (at cost of latency)

---

## ðŸ” Retrieval Methods

### 1. Vector Search (Semantic)

**How it works**:
- Converts query and documents to dense vector embeddings
- Measures cosine similarity in embedding space
- Returns most similar documents

**Pros**:
- Understands semantic meaning
- Works with paraphrases and synonyms
- Good for conceptual queries

**Cons**:
- May miss exact keywords
- Dependent on embedding model quality
- Higher latency due to embedding generation

**Best for**: `"What are the environmental benefits of renewable energy?"`

### 2. Self-Query Retriever

**How it works**:
- LLM analyzes query to extract metadata filters
- Constructs structured database query
- Performs filtered vector search

**Pros**:
- Handles complex natural language filters
- Combines semantic search with structured filtering
- No need for users to specify filters manually

**Cons**:
- Extra LLM call adds latency
- LLM may misinterpret complex queries
- Requires well-structured metadata

**Best for**: `"Show me solar power papers from 2024 about government policy"`

### 3. BM25 Keyword Search

**How it works**:
- Traditional TF-IDF based ranking
- Scores documents by keyword frequency and rarity
- Fast in-memory computation

**Pros**:
- Very fast (50-150ms)
- Good for exact keyword matching
- No external API calls

**Cons**:
- No semantic understanding
- Misses paraphrases
- Sensitive to vocabulary mismatch

**Best for**: `"photovoltaic efficiency coefficient"`

### 4. Hybrid Search

**How it works**:
- Runs BM25 and vector search in parallel
- Merges results with weighted scoring
- Deduplicates and re-ranks

**Pros**:
- Best of both worlds
- Robust to different query types
- Configurable weighting

**Cons**:
- Higher latency (both methods run)
- More complex to tune
- May not excel at either extreme

**Best for**: `"solar panel installation cost 2024"` (mix of keywords and concepts)

### 5. Hypothetical Document Embeddings (HyDE)

**How it works**:
- LLM generates hypothetical document that would answer the query
- Embeds the hypothetical document
- Searches for similar actual documents

**Pros**:
- Great for abstract/conceptual queries
- Bridges vocabulary gap
- Can find relevant docs with different wording

**Cons**:
- Highest latency (LLM + embedding + search)
- May generate incorrect hypotheticals
- Resource intensive

**Best for**: `"How can we reduce carbon emissions in energy production?"`

---

## âš¡ Augmentation Techniques

### 1. Cross-Encoder Reranking

**Model**: `cross-encoder/ms-marco-MiniLM-L-6-v2`

**Process**:
```python
# Initial retrieval: 50 candidates (fast)
candidates = retriever.search(query, top_k=50)

# Reranking: 50 pairs scored (slower but more accurate)
for doc in candidates:
    score = cross_encoder.predict([[query, doc.content]])
    doc.reranked_score = score

# Final: Top 10 by reranked score
final_results = sorted(candidates, key=lambda x: x.reranked_score)[:10]
```

**Impact**: +15-30% accuracy, +200-500ms latency

### 2. Context Compression

**Process**:
```python
# Before compression
doc_content = "Long document with 2000 tokens... lots of irrelevant information..."

# LLM extracts relevant parts
compressed = llm.invoke(
    f"Extract only content relevant to: {query}\n\nDocument: {doc_content}"
)

# After compression
compressed_content = "Relevant excerpt with 300 tokens..."
```

**Impact**:
- 60-80% token reduction
- Faster answer generation
- Lower cost for downstream LLM calls

### 3. Query Expansion

**Process**:
```python
# Original query
original = "solar panels"

# LLM expands
expanded = llm.invoke(f"Generate synonyms and related terms for: {original}")

# Result
expanded = "solar panels, photovoltaic cells, solar arrays, PV modules, solar energy systems"

# Re-retrieve with expanded query
results = retriever.search(expanded, top_k=10)
```

**Impact**:
- +10-20% recall
- May reduce precision
- +500-800ms latency

---

## âš™ï¸ Configuration

### Environment Variables

See `.env.example` for full list. Key configurations:

#### OpenAI
```bash
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.0
```

#### LangChain/LangSmith
```bash
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=self-querying-retriever
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
```

#### LangFuse (Self-Hosted)
```bash
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=http://langfuse:3000
```

#### Database
```bash
POSTGRES_DB=self_querying_retriever
POSTGRES_USER=postgres
POSTGRES_PASSWORD=change-in-production
POSTGRES_HOST=db
POSTGRES_PORT=5432
DATABASE_URL=postgresql://postgres:postgres@db:5432/self_querying_retriever
```

#### Redis
```bash
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2
```

#### ChromaDB
```bash
CHROMA_HOST=chromadb
CHROMA_PORT=8000
CHROMA_CLIENT_AUTH_CREDENTIALS=
CHROMA_COLLECTION_NAME=documents
```

### Django Settings

Key settings in `backend/config/settings.py`:

```python
# Retrieval Configuration
RETRIEVAL_SETTINGS = {
    'DEFAULT_TOP_K': 5,
    'MAX_TOP_K': 50,
    'DEFAULT_METHOD': 'vector',
    'ENABLE_CACHING': True,
    'CACHE_TTL': 3600,  # 1 hour
}

# Augmentation Settings
AUGMENTATION_SETTINGS = {
    'RERANKING_MODEL': 'cross-encoder/ms-marco-MiniLM-L-6-v2',
    'COMPRESSION_MAX_TOKENS': 500,
    'EXPANSION_MAX_TERMS': 10,
}

# Rate Limiting
RATE_LIMIT = {
    'QUERIES_PER_MINUTE': 10,
    'UPLOADS_PER_HOUR': 100,
}
```

### Frontend Configuration

`frontend/.env`:
```bash
VITE_API_URL=http://localhost:3087
VITE_WS_URL=ws://localhost:3087
VITE_ENABLE_ANALYTICS=true
VITE_DEFAULT_TOP_K=5
```

---

## ðŸ’» Development

### Backend Development (Django)

```bash
# Setup
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Environment
cp ../.env.example .env
# Edit .env with your settings

# Database
python manage.py migrate
python manage.py createsuperuser
python manage.py seed_documents --no-input

# Run development server
python manage.py runserver 0.0.0.0:8083

# Run tests
pytest
pytest tests/test_retrievers.py -v

# Code quality
black .
flake8 .
mypy .
```

### Frontend Development (React)

```bash
# Setup
cd frontend
npm install

# Environment
cp .env.example .env
# Edit .env with API URL

# Run development server (with hot reload)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview

# Lint
npm run lint

# Type check
npm run type-check
```

### API Gateway Development (Node.js)

```bash
# Setup
cd api-gateway
npm install

# Environment
cp .env.example .env

# Run development server (with auto-restart)
npm run dev

# Build TypeScript
npm run build

# Run production
npm start

# Lint
npm run lint
```

### Running Tests

```bash
# Backend tests
docker-compose exec backend pytest
docker-compose exec backend pytest --cov=retriever tests/

# Frontend tests
docker-compose exec frontend npm test

# Integration tests
docker-compose exec backend pytest tests/integration/

# E2E tests (requires frontend running)
cd frontend
npm run test:e2e
```

### Database Management

```bash
# Create migration
docker-compose exec backend python manage.py makemigrations

# Apply migrations
docker-compose exec backend python manage.py migrate

# Reset database
docker-compose exec backend python manage.py flush

# Backup database
docker-compose exec db pg_dump -U postgres self_querying_retriever > backup.sql

# Restore database
cat backup.sql | docker-compose exec -T db psql -U postgres self_querying_retriever
```

### Celery Management

```bash
# View active workers
docker-compose exec celery-worker celery -A config inspect active

# View scheduled tasks
docker-compose exec celery-beat celery -A config inspect scheduled

# Purge all tasks
docker-compose exec celery-worker celery -A config purge

# Monitor in terminal
docker-compose exec celery-worker celery -A config events
```

---

## ðŸ“ Project Structure

```
self-querying-retriever/
â”œâ”€â”€ docs/                                    # Documentation
â”‚   â”œâ”€â”€ technical-architecture.drawio        # Architecture diagram
â”‚   â”œâ”€â”€ technical-architecture-presentation.md  # Slide deck
â”‚   â””â”€â”€ api-reference.md                     # API docs
â”‚
â”œâ”€â”€ frontend/                                # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                      # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ common/                      # Buttons, inputs, cards
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/                      # Header, sidebar, footer
â”‚   â”‚   â”‚   â””â”€â”€ query/                       # Query-specific components
â”‚   â”‚   â”œâ”€â”€ pages/                           # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QueryPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CollectionsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentVisualization.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalyticsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QueryHistory.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PipelinesPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ SettingsPage.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/                           # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useQuery.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useDocuments.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts
â”‚   â”‚   â”‚   â””â”€â”€ useAnalytics.ts
â”‚   â”‚   â”œâ”€â”€ services/                        # API clients
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts                       # Axios instance
â”‚   â”‚   â”‚   â”œâ”€â”€ queryService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ documentService.ts
â”‚   â”‚   â”‚   â””â”€â”€ websocketService.ts
â”‚   â”‚   â”œâ”€â”€ store/                           # Zustand state management
â”‚   â”‚   â”‚   â”œâ”€â”€ queryStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ uiStore.ts
â”‚   â”‚   â”œâ”€â”€ types/                           # TypeScript types
â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ document.ts
â”‚   â”‚   â”‚   â””â”€â”€ agent.ts
â”‚   â”‚   â”œâ”€â”€ utils/                           # Utility functions
â”‚   â”‚   â”œâ”€â”€ App.tsx                          # Root component
â”‚   â”‚   â””â”€â”€ main.tsx                         # Entry point
â”‚   â”œâ”€â”€ public/                              # Static assets
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ api-gateway/                             # Node.js API Gateway
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/                          # Express routes
â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.ts
â”‚   â”‚   â”‚   â””â”€â”€ analytics.ts
â”‚   â”‚   â”œâ”€â”€ middleware/                      # Middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ rateLimiter.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ errorHandler.ts
â”‚   â”‚   â”‚   â””â”€â”€ logger.ts
â”‚   â”‚   â”œâ”€â”€ services/                        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ proxyService.ts
â”‚   â”‚   â”‚   â””â”€â”€ websocketManager.ts
â”‚   â”‚   â”œâ”€â”€ config/                          # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ types/                           # TypeScript types
â”‚   â”‚   â””â”€â”€ server.ts                        # Entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ backend/                                 # Django Backend
â”‚   â”œâ”€â”€ config/                              # Django project settings
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â”œâ”€â”€ asgi.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retriever/                           # Main retrieval app
â”‚   â”‚   â”œâ”€â”€ agents/                          # LangGraph multi-agent system
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py                     # StateGraph definition
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py                     # Agent node implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                     # State definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ tools.py                     # LangGraph tools
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py                   # Prompt templates
â”‚   â”‚   â”‚   â””â”€â”€ callbacks.py                 # Custom callbacks
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py              # ChromaDB integration
â”‚   â”‚   â”‚   â”œâ”€â”€ retrievers.py                # 5 retrieval implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ augmentation.py              # Reranking, compression, expansion
â”‚   â”‚   â”‚   â””â”€â”€ observability.py             # LangSmith + LangFuse
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a2a/                             # Agent-to-Agent protocol
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cards.py                     # Agent card definitions
â”‚   â”‚   â”‚   â””â”€â”€ views.py                     # A2A discovery endpoints
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models.py                        # Django ORM models
â”‚   â”‚   â”œâ”€â”€ serializers.py                   # DRF serializers
â”‚   â”‚   â”œâ”€â”€ views.py                         # API views
â”‚   â”‚   â”œâ”€â”€ urls.py                          # URL routing
â”‚   â”‚   â”œâ”€â”€ tasks.py                         # Celery tasks
â”‚   â”‚   â”œâ”€â”€ admin.py                         # Django admin
â”‚   â”‚   â””â”€â”€ tests/                           # Unit tests
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/                           # Document management app
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ tasks.py                         # Document processing tasks
â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                           # Analytics app
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ mcp-server/                              # Model Context Protocol server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ tools/                           # MCP tool definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ search.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts
â”‚   â”‚   â”‚   â””â”€â”€ rerank.ts
â”‚   â”‚   â”œâ”€â”€ resources/                       # MCP resource definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ collections.ts
â”‚   â”‚   â”‚   â””â”€â”€ documents.ts
â”‚   â”‚   â”œâ”€â”€ config.ts
â”‚   â”‚   â””â”€â”€ index.ts                         # Entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ scripts/                                 # Utility scripts
â”‚   â”œâ”€â”€ init-db.sh                           # Database initialization
â”‚   â””â”€â”€ seed-data.py                         # Data seeding
â”‚
â”œâ”€â”€ notebooks/                               # Jupyter notebooks
â”‚   â””â”€â”€ W6_Adv_RAG_Rec_NB.ipynb             # Original notebook
â”‚
â”œâ”€â”€ .env.example                             # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml                       # Service orchestration
â”œâ”€â”€ README.md                                # This file
â””â”€â”€ LICENSE
```

---

## ðŸ“Š Observability

### LangSmith Integration

LangSmith provides comprehensive LLM tracing:

```python
# Enable in .env
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=self-querying-retriever
```

**Features**:
- Trace every LLM call
- View prompt and completion
- Track token usage and cost
- Debug chain execution
- Compare different runs

**Access**: https://smith.langchain.com

### LangFuse Dashboard

Self-hosted observability at http://localhost:3085:

**Capabilities**:
- Real-time execution timeline
- Agent interaction graphs
- Performance bottleneck identification
- Cost tracking per query
- Custom metrics and dashboards

**Setup**:
```bash
# Default credentials
Email: admin@example.com
Password: changeme123

# Change password on first login
```

### Celery Flower

Monitor Celery tasks at http://localhost:5583:

- Worker status and health
- Task queue lengths
- Task execution times
- Failed task analysis
- Real-time task monitoring

### Application Logging

Structured JSON logs:

```bash
# View backend logs
docker-compose logs -f backend

# View specific log level
docker-compose logs backend | grep ERROR

# View with timestamps
docker-compose logs -f --timestamps backend

# Follow Celery worker logs
docker-compose logs -f celery-worker
```

---

## âš¡ Performance

### Benchmark Results

Tested on: MacBook Pro M1, 16GB RAM, 10Gbps network

| Method | Avg Latency | p95 Latency | Throughput |
|--------|-------------|-------------|------------|
| Vector Search | 280ms | 450ms | 35 req/s |
| BM25 | 95ms | 180ms | 105 req/s |
| Hybrid | 340ms | 520ms | 29 req/s |
| Self-Query | 720ms | 1100ms | 14 req/s |
| HyDE | 1150ms | 1800ms | 9 req/s |

**With Reranking**: +250ms average
**With Compression**: +400ms average
**With Expansion**: +650ms average (includes re-retrieval)

### Optimization Tips

#### 1. Caching
```python
# Enable Redis caching in settings.py
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/0',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        }
    }
}

# Cache query results for 1 hour
@cache_page(60 * 60)
def query_view(request):
    ...
```

#### 2. Connection Pooling
```python
# PostgreSQL connection pooling
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'CONN_MAX_AGE': 600,  # 10 minutes
        'OPTIONS': {
            'MAX_CONNS': 20,
        }
    }
}
```

#### 3. Async Processing
```python
# Use Celery for slow operations
from retriever.tasks import process_document_upload

# Sync (blocks request)
process_document_upload(docs)

# Async (returns immediately)
process_document_upload.delay(docs)
```

#### 4. Batch Operations
```python
# Instead of:
for doc in documents:
    collection.add(doc)

# Do:
collection.add_many(documents)  # Single DB call
```

#### 5. Index Optimization
```sql
-- Add indexes for common queries
CREATE INDEX idx_document_collection ON retriever_document(collection_name);
CREATE INDEX idx_document_created ON retriever_document(created_at DESC);
CREATE INDEX idx_query_method ON retriever_query(retrieval_method);
CREATE INDEX idx_metadata_year ON retriever_documentmetadata(year);
```

---

## ðŸ› Troubleshooting

### Common Issues

#### 1. "Connection refused" errors

**Problem**: Services not ready

**Solution**:
```bash
# Wait for all services to start
docker-compose up -d
docker-compose logs -f  # Wait for "Application startup complete"

# Check service health
docker-compose ps
curl http://localhost:8083/api/health/
```

#### 2. "OpenAI API key not found"

**Problem**: Missing or invalid API key

**Solution**:
```bash
# Check .env file
cat .env | grep OPENAI_API_KEY

# Set key if missing
echo "OPENAI_API_KEY=sk-..." >> .env

# Restart backend
docker-compose restart backend
```

#### 3. ChromaDB connection errors

**Problem**: ChromaDB not initialized

**Solution**:
```bash
# Check ChromaDB logs
docker-compose logs chromadb

# Restart ChromaDB
docker-compose restart chromadb

# Verify connection
curl http://localhost:8000/api/v1/heartbeat
```

#### 4. Celery tasks not processing

**Problem**: Celery worker offline or Redis connection issue

**Solution**:
```bash
# Check worker status
docker-compose logs celery-worker

# Check Redis connection
docker-compose exec backend python -c "import redis; r=redis.Redis(host='redis'); r.ping()"

# Restart worker
docker-compose restart celery-worker
```

#### 5. Frontend shows "API not available"

**Problem**: API gateway or backend down

**Solution**:
```bash
# Check API gateway
curl http://localhost:3087/health

# Check backend
curl http://localhost:8083/api/health/

# Check logs
docker-compose logs api-gateway backend

# Restart if needed
docker-compose restart api-gateway backend
```

### Debug Mode

Enable debug logging:

```bash
# Backend debug mode
# In .env:
DJANGO_DEBUG=True
DJANGO_LOG_LEVEL=DEBUG

# Restart
docker-compose restart backend

# View detailed logs
docker-compose logs -f backend
```

### Performance Issues

If experiencing slow queries:

1. **Check database indexes**:
```sql
SELECT * FROM pg_stat_user_indexes WHERE schemaname = 'public';
```

2. **Monitor ChromaDB**:
```bash
docker stats chromadb
```

3. **Check Redis memory**:
```bash
docker-compose exec redis redis-cli INFO memory
```

4. **Profile slow queries**:
```python
# In Django shell
from django.db import connection
from django.test.utils import override_settings

with override_settings(DEBUG=True):
    # Run your query
    len(connection.queries)  # Number of queries
    connection.queries[-1]  # Last query
```

---

## ðŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

### Development Workflow

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make changes and test**:
   ```bash
   # Backend tests
   docker-compose exec backend pytest

   # Frontend tests
   docker-compose exec frontend npm test
   ```
4. **Commit with conventional commits**:
   ```bash
   git commit -m "feat: add new retrieval method"
   git commit -m "fix: resolve ChromaDB connection issue"
   git commit -m "docs: update API documentation"
   ```
5. **Push and create PR**: `git push origin feature/amazing-feature`

### Code Style

**Python (Backend)**:
- Follow PEP 8
- Use Black for formatting: `black .`
- Type hints required: `mypy .`
- Docstrings for public functions

**TypeScript (Frontend/Gateway)**:
- Follow ESLint rules
- Use Prettier: `prettier --write .`
- Explicit types (no `any`)

**Commit Messages**:
- Use conventional commits: `feat:`, `fix:`, `docs:`, `refactor:`, etc.

### Adding New Features

#### New Retrieval Method

1. Implement in `backend/retriever/services/retrievers.py`:
```python
class MyNewRetriever(BaseRetriever):
    def retrieve(self, query: str, top_k: int = 5) -> List[Dict]:
        # Your implementation
        pass
```

2. Add node in `backend/retriever/agents/nodes.py`:
```python
def my_new_retriever_node(state: RetrieverState) -> RetrieverState:
    retriever = MyNewRetriever()
    results = retriever.retrieve(state["query"])
    state["documents"] = results
    return state
```

3. Update graph in `backend/retriever/agents/graph.py`:
```python
graph.add_node("my_new_retriever", my_new_retriever_node)
graph.add_edge("supervisor", "my_new_retriever")
```

4. Add tests in `backend/retriever/tests/test_retrievers.py`

#### New Frontend Page

1. Create page component in `frontend/src/pages/MyPage.tsx`
2. Add route in `frontend/src/App.tsx`
3. Add navigation link in `frontend/src/components/layout/Sidebar.tsx`
4. Create API service if needed in `frontend/src/services/myService.ts`

---

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ðŸ“ž Support & Contact

### Documentation

- **Architecture Diagram**: `docs/technical-architecture.drawio`
- **Presentation**: `docs/technical-architecture-presentation.md`
- **API Reference**: View at http://localhost:8083/api/docs/ when running

### Community

- **GitHub Issues**: [Report bugs or request features](https://github.com/yourusername/self-querying-retriever/issues)
- **GitHub Discussions**: [Ask questions and share ideas](https://github.com/yourusername/self-querying-retriever/discussions)
- **Email**: [your-email@example.com]

### Acknowledgments

Built with:
- [LangChain](https://langchain.com) - LLM framework
- [LangGraph](https://langchain-ai.github.io/langgraph/) - Agent orchestration
- [Django](https://www.djangoproject.com/) - Backend framework
- [React](https://react.dev/) - Frontend framework
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [OpenAI](https://openai.com/) - Embeddings and LLM

---

## ðŸ—ºï¸ Roadmap

### v1.1 (Q2 2024)
- [ ] Multi-user authentication and RBAC
- [ ] Custom embedding model support
- [ ] Multi-modal retrieval (images, PDFs)
- [ ] Query history export (CSV, JSON)
- [ ] A/B testing framework

### v1.2 (Q3 2024)
- [ ] Federated search across multiple collections
- [ ] Graph-based retrieval (knowledge graphs)
- [ ] Active learning for retrieval optimization
- [ ] Multi-lingual support
- [ ] Fine-tuned reranking models

### v2.0 (Q4 2024)
- [ ] Real-time collaborative filtering
- [ ] Reinforcement learning from user feedback
- [ ] Explainable AI for result ranking
- [ ] Integration with external knowledge bases
- [ ] Auto-scaling based on load
- [ ] Kubernetes deployment

---

<div align="center">

**â­ Star this repo if you find it helpful!**

[Report Bug](https://github.com/yourusername/self-querying-retriever/issues) â€¢
[Request Feature](https://github.com/yourusername/self-querying-retriever/issues) â€¢
[Documentation](https://github.com/yourusername/self-querying-retriever/wiki)

</div>
